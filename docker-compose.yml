version: '3.8'

services:
    # ----------------------------------------------------------------
    # Infrastructure Services
    # ----------------------------------------------------------------
    redis:
        image: redis:7-alpine
        container_name: riskoptimizer-redis
        ports:
            - '6379:6379'
        volumes:
            - redis_data:/data
        command: redis-server --appendonly yes
        healthcheck:
            test: ['CMD', 'redis-cli', 'ping']
            interval: 10s
            timeout: 5s
            retries: 5
        networks:
            - riskoptimizer-network
        restart: unless-stopped

    postgres:
        image: postgres:15-alpine
        container_name: riskoptimizer-postgres
        environment:
            POSTGRES_DB: riskoptimizer
            POSTGRES_USER: riskoptimizer
            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-riskoptimizer123}
        ports:
            - '5432:5432'
        volumes:
            - postgres_data:/var/lib/postgresql/data
            # Assuming init.sql exists in the deployment directory relative to the backend context
            - ./code/backend/deployment/init.sql:/docker-entrypoint-initdb.d/init.sql
        healthcheck:
            test: ['CMD-SHELL', 'pg_isready -U riskoptimizer']
            interval: 10s
            timeout: 5s
            retries: 5
        networks:
            - riskoptimizer-network
        restart: unless-stopped

    # ----------------------------------------------------------------
    # Backend Services (API, Worker, Scheduler)
    # ----------------------------------------------------------------
    api:
        build:
            context: ./code/backend
            dockerfile: Dockerfile
            target: production
        container_name: riskoptimizer-api
        environment:
            - DATABASE_URL=postgresql://riskoptimizer:${POSTGRES_PASSWORD:-riskoptimizer123}@postgres:5432/riskoptimizer
            - REDIS_URL=redis://redis:6379/0
            - CELERY_RESULT_BACKEND=redis://redis:6379/1
            - ENVIRONMENT=production
        ports:
            - '8000:8000' # Main API port, exposed to Nginx
        depends_on:
            postgres:
                condition: service_healthy
            redis:
                condition: service_healthy
        volumes:
            - ./code/backend/logs:/app/logs
            - ./code/backend/tmp:/app/tmp
        healthcheck:
            test: ['CMD', 'curl', '-f', 'http://localhost:8000/health']
            interval: 30s
            timeout: 10s
            retries: 3
        networks:
            - riskoptimizer-network
        restart: unless-stopped

    worker:
        build:
            context: ./code/backend
            dockerfile: Dockerfile
            target: worker
        container_name: riskoptimizer-worker
        environment:
            - DATABASE_URL=postgresql://riskoptimizer:${POSTGRES_PASSWORD:-riskoptimizer123}@postgres:5432/riskoptimizer
            - REDIS_URL=redis://redis:6379/0
            - CELERY_RESULT_BACKEND=redis://redis:6379/1
            - ENVIRONMENT=production
        depends_on:
            postgres:
                condition: service_healthy
            redis:
                condition: service_healthy
        volumes:
            - ./code/backend/logs:/app/logs
            - ./code/backend/tmp:/app/tmp
        networks:
            - riskoptimizer-network
        restart: unless-stopped
        # deploy: # Removed deploy block for simpler docker-compose setup
        #   replicas: 2

    beat:
        build:
            context: ./code/backend
            dockerfile: Dockerfile
            target: beat
        container_name: riskoptimizer-beat
        environment:
            - DATABASE_URL=postgresql://riskoptimizer:${POSTGRES_PASSWORD:-riskoptimizer123}@postgres:5432/riskoptimizer
            - REDIS_URL=redis://redis:6379/0
            - CELERY_RESULT_BACKEND=redis://redis:6379/1
            - ENVIRONMENT=production
        depends_on:
            postgres:
                condition: service_healthy
            redis:
                condition: service_healthy
        volumes:
            - ./code/backend/logs:/app/logs
        networks:
            - riskoptimizer-network
        restart: unless-stopped

    flower:
        image: mher/flower:0.9.7
        container_name: riskoptimizer-flower
        environment:
            - CELERY_BROKER_URL=redis://redis:6379/0
            - FLOWER_PORT=5555
        ports:
            - '5555:5555'
        depends_on:
            redis:
                condition: service_healthy
        networks:
            - riskoptimizer-network
        restart: unless-stopped

    # ----------------------------------------------------------------
    # Frontend and Proxy
    # ----------------------------------------------------------------
    web-frontend:
        build:
            context: ./code/web-frontend
            dockerfile: Dockerfile # Assuming a simple Dockerfile for Vite build/serve
        container_name: riskoptimizer-web-frontend
        environment:
            # The web-frontend uses a proxy to /api, which needs to point to the backend API service.
            # The host in vite.config.js is 'localhost:5000', which we'll assume is the internal API port
            # if the API service was running on port 5000. The existing compose file uses 8000.
            # We'll use the service name 'api' and port 8000 for the internal connection.
            VITE_API_URL: http://api:8000
        ports:
            - '3000:3000' # Vite's default dev port
        networks:
            - riskoptimizer-network
        restart: unless-stopped
        command: ['npm', 'run', 'dev', '--', '--host'] # Start Vite development server

    nginx:
        image: nginx:alpine
        container_name: riskoptimizer-nginx
        ports:
            - '80:80'
            - '443:443'
        volumes:
            # Assuming nginx.conf and ssl directory are relative to the project root
            - ./code/backend/deployment/nginx.conf:/etc/nginx/nginx.conf
            - ./code/backend/deployment/ssl:/etc/nginx/ssl
            # Mount the built frontend static files here for production
            # - ./code/web-frontend/dist:/usr/share/nginx/html
        depends_on:
            - api
            - web-frontend # Depends on frontend if serving static files from it
        networks:
            - riskoptimizer-network
        restart: unless-stopped

    # ----------------------------------------------------------------
    # Monitoring Stack
    # ----------------------------------------------------------------
    prometheus:
        image: prom/prometheus:latest
        container_name: riskoptimizer-prometheus
        ports:
            - '9090:9090'
        volumes:
            - ./code/backend/deployment/prometheus.yml:/etc/prometheus/prometheus.yml
            - prometheus_data:/prometheus
        command:
            - '--config.file=/etc/prometheus/prometheus.yml'
            - '--storage.tsdb.path=/prometheus'
            - '--web.enable-lifecycle'
        networks:
            - riskoptimizer-network
        restart: unless-stopped

    grafana:
        image: grafana/grafana:latest
        container_name: riskoptimizer-grafana
        ports:
            - '3001:3000' # Exposed on 3001 to avoid conflict with web-frontend dev server
        environment:
            - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin123}
        volumes:
            - grafana_data:/var/lib/grafana
            - ./code/backend/deployment/grafana/dashboards:/etc/grafana/provisioning/dashboards
            - ./code/backend/deployment/grafana/datasources:/etc/grafana/provisioning/datasources
        depends_on:
            - prometheus
        networks:
            - riskoptimizer-network
        restart: unless-stopped

# ----------------------------------------------------------------
# Volumes and Networks
# ----------------------------------------------------------------
volumes:
    postgres_data:
    redis_data:
    prometheus_data:
    grafana_data:

networks:
    riskoptimizer-network:
        driver: bridge
